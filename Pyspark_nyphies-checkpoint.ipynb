{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b967e894",
   "metadata": {},
   "source": [
    "## Instantiate Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b56151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "c = pyspark.SparkConf().setAppName(\"test_app\").setMaster(\"local\")\n",
    "sc = pyspark.SparkContext(conf = c)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f44d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b515c7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6ae71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sk = spark.read.csv(\"nphies.csv\",inferSchema = True , header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sk.printSchema() ## Checks DataType "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d382e",
   "metadata": {},
   "source": [
    "## Changed all Date Columns to Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae75fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_date_convert = ['Provider Contract Start Date',\n",
    " 'Provider Contract End Date',\n",
    " 'Policy Issue Date',\n",
    " 'Policy Start Date',\n",
    " 'Policy Expiry Date',\n",
    " 'Received Date',\n",
    " 'Treatment Date']\n",
    "\n",
    " #['Item Date','Settlement Date'] contains Mixed datatype (mm/dd/yyyy & strings)\n",
    " #['Claim Approval Date'] contains mm/dd/yyyy hh:mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877fe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lambda function to convert date to \"mm/dd/yyyy\" format\n",
    "convert_to_date_format = lambda col_name: to_date(col(col_name), \"MM/dd/yyyy\").alias(col_name)\n",
    "\n",
    "# Apply the conversion to selected columns\n",
    "converted_df = data_sk.select(*[convert_to_date_format(col_name) if col_name in columns_date_convert else col(col_name) for col_name in data_sk.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baece986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2a393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485cf6d",
   "metadata": {},
   "source": [
    "## Business Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d245f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Columns as Business Requirements \n",
    "selected_columns = ['Provider Code','Provider Name','Provider Class','Provider City','Customer Name','Policy Number','Policy Start Date','Policy Expiry Date','Member Code','Member Name','Member Relationship','Member National Id','Member DOB',\n",
    "                    'Marital Status','Gender','Nationality','Mobile',\n",
    "                    'Diagnosis','Diagnosis Code','Claim Number','Treatment Date','Service Type',\n",
    "                    'Item Name','Price','Quantity','Prv Net Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7811c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f241a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datafrome of selected columns\n",
    "selected_df= converted_df.select(*selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af8e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Diagnosis column\n",
    "# selected_df.select( 'Diagnosis','Diagnosis Code').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3781aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "Selected_columns_cleaned = selected_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bee88",
   "metadata": {},
   "source": [
    "### Checking for total Duplicated Records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba3bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = selected_df.count()\n",
    "# cleaned = Selected_columns_cleaned.count()\n",
    "# total_no_duplicates = raw - cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "631830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_no_duplicates # There are 132,049 Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2bac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "#Selected_columns_cleaned.select('Member DOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e53193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Age Column\n",
    "Selected_columns_cleaned = Selected_columns_cleaned.withColumn('Member DOB', to_date(col('Member DOB'), 'MM/dd/yyyy')) \\\n",
    "       .withColumn('Age', (datediff(col('Treatment Date'), col('Member DOB')) / 365).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2ccdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected_columns_cleaned.select('Age').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63321581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected_columns_cleaned.count() # There are 2796425 Cleaned Records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84208a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_columns_cleaned.createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c9230",
   "metadata": {},
   "source": [
    "## Medication Abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29838fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Spark SQL\n",
    "Member_Abuse = spark.sql(\"\"\"\n",
    "SELECT `Member Code`, `Member Name`, `Item Name`, `Treatment Date`, Duplicate_Treatment_Date,\n",
    "       DATEDIFF(Duplicate_Treatment_Date, `Treatment Date`) AS Waiting_period\n",
    "FROM (\n",
    "    SELECT *,\n",
    "           LEAD(`Treatment Date`) OVER (PARTITION BY `Member Code`, `Item Name` ORDER BY `Treatment Date`) AS Duplicate_Treatment_Date\n",
    "    FROM table\n",
    "    WHERE `Service Type` = 'Pharmacy'\n",
    ") AS subquery\n",
    "WHERE DATEDIFF(Duplicate_Treatment_Date, `Treatment Date`) BETWEEN 1 AND 25;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd9a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Member_Abuse.show() # There are 66,509 Claims with member Abuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9afaed",
   "metadata": {},
   "source": [
    "## Splitting Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e25e09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_claims = spark.sql(\"\"\"\n",
    "SELECT \n",
    "        `Member Code`,\n",
    "        `Provider Code`,\n",
    "        COUNT(*) AS Number_of_claims\n",
    "FROM(\n",
    "SELECT\n",
    "    *,\n",
    "    CASE\n",
    "        WHEN Date_diff IS NULL THEN 0\n",
    "        WHEN Date_diff < 1 OR Date_diff > 30 THEN 0\n",
    "        ELSE 1\n",
    "    END AS Date_Flag\n",
    "FROM (\n",
    "    SELECT\n",
    "        `Member Code`,\n",
    "        `Provider Code`,\n",
    "        `Treatment Date`,\n",
    "        LEAD(`Treatment Date`) OVER (PARTITION BY `Member Code` ORDER BY `Treatment Date`) AS Next_date,\n",
    "        DATEDIFF(LEAD(`Treatment Date`) OVER (PARTITION BY `Member Code` ORDER BY `Treatment Date`), `Treatment Date`) AS Date_diff\n",
    "    FROM\n",
    "        Table\n",
    ") AS subquery\n",
    "WHERE (CASE\n",
    "        WHEN Date_diff IS NULL THEN 0\n",
    "        WHEN Date_diff < 1 OR Date_diff > 30 THEN 0\n",
    "        ELSE 1\n",
    "    END) = 1\n",
    ")\n",
    "GROUP BY `Member Code`, `Provider Code`\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8898d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56745"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # split_claims.count() There are 56745 of the occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f335e3c",
   "metadata": {},
   "source": [
    "## Member Abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c504e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "MemberAbuse = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        `Member Code`, \n",
    "        `Provider Code`, \n",
    "        `Treatment Date`,\n",
    "        Claims_Count\n",
    "    FROM (\n",
    "        SELECT \n",
    "            `Member Code`, \n",
    "            `Provider Code`, \n",
    "            `Treatment Date`,\n",
    "            Claims_Count,\n",
    "            DATEDIFF(`Treatment Date`, LAG(`Treatment Date`, 1) OVER (PARTITION BY `Member Code`, `Service Type` ORDER BY `Treatment Date`)) AS Date_Diff\n",
    "        FROM (\n",
    "            SELECT \n",
    "                `Member Code`, \n",
    "                `Provider Code`, \n",
    "                `Service Type`, \n",
    "                `Treatment Date`,\n",
    "                COUNT(*) OVER (PARTITION BY `Member Code`, `Service Type` ORDER BY `Treatment Date`) AS Claims_Count\n",
    "            FROM \n",
    "                table\n",
    "        ) AS subquery\n",
    "    ) AS filtered_data\n",
    "    WHERE \n",
    "        Date_Diff <= 30\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6974df15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1912345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MemberAbuse.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b7be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MemberAbuse.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48506d",
   "metadata": {},
   "source": [
    "## Different Area or City Claims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6bdfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CityClaims = spark.sql(\"\"\"\n",
    "    WITH rod_with_diff AS (\n",
    "        SELECT *,\n",
    "            DATEDIFF(`Treatment Date`, \n",
    "                     LAG(`Treatment Date`, 1) OVER (PARTITION BY `Member Code`, `Member Name`, `Diagnosis` ORDER BY `Treatment Date`)) AS date_diff,\n",
    "            LAG(`Provider City`, 1) OVER (PARTITION BY `Member Code`, `Member Name`, `Diagnosis` ORDER BY `Treatment Date`) AS prev_provider_city\n",
    "        FROM table\n",
    "    )\n",
    "    SELECT \n",
    "         `Member Code`,\n",
    "         `Member Name`,\n",
    "         `Diagnosis`,\n",
    "         date_diff,\n",
    "         `Treatment Date`,\n",
    "         `Provider City`\n",
    "    FROM rod_with_diff\n",
    "    WHERE date_diff <= 7 AND `Provider City` != prev_provider_city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "abecb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a2ae2",
   "metadata": {},
   "source": [
    "## Chronic Disease at Young Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b3d590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chronic_Age = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    `Member Code`,\n",
    "    `Diagnosis`,\n",
    "    `Age`,\n",
    "    COUNT(*) AS `Claim Count`\n",
    "FROM\n",
    "    table\n",
    "WHERE\n",
    "    `Age` < 30\n",
    "    AND\n",
    "    (`Diagnosis` LIKE '%hypertension%' \n",
    "    OR `Diagnosis` LIKE '%dyslipidemia%' \n",
    "    OR `Diagnosis` LIKE '%ischemic heart disease%' \n",
    "    OR `Diagnosis` LIKE '%chronic obstructive pulmonary disease%')\n",
    "GROUP BY\n",
    "    `Member Code`,\n",
    "    `Diagnosis`,\n",
    "    `Age`\n",
    "ORDER BY\n",
    "    `Claim Count`\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "903b4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chronic_Age.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d5603",
   "metadata": {},
   "source": [
    "## Charging Consultation within the follow-up Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b7f2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Table Capture data that groups member code and diagnosis \n",
    "\n",
    "con_2 = spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        *,\n",
    "        LEAD(`Member Code`) OVER (ORDER BY `Treatment Date`) AS Next_member_code,\n",
    "        LEAD(`Diagnosis code`) OVER (ORDER BY `Treatment Date`) AS Next_daignosis,\n",
    "        LEAD(`Treatment date`) OVER (PARTITION BY `Member Code`, `Diagnosis code` ORDER BY `Treatment Date`) AS next_treatment_date,\n",
    "        DATEDIFF(LEAD(`Treatment date`) OVER (PARTITION BY `Member Code`, `Diagnosis code` ORDER BY `Treatment Date`), `Treatment date`) AS date_diff\n",
    "    FROM \n",
    "        table\n",
    ") AS subquery\n",
    " \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "496da112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table captures consultation from same member and diagnosis with 14 days period \n",
    "\n",
    "Cons_Df = con_2.select('Member Code','Next_member_code', 'Diagnosis code', 'Next_daignosis', 'next_treatment_date', 'date_diff', 'Service Type', 'Treatment date') \\\n",
    "    .filter((con_2['Service Type'] == 'Consultation') & (con_2['Member Code'] == con_2['Next_member_code']) & (con_2['Member Code'] == con_2['Next_member_code']) \n",
    "           & (col('date_diff').between(1, 14))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9051e",
   "metadata": {},
   "source": [
    "## Maternity Services After Delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a5339ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maternity_Delivery = spark.sql(\"\"\"\n",
    "WITH delivery_table AS (\n",
    "    SELECT \n",
    "       `Treatment Date`,\n",
    "       `Member Code`,\n",
    "       `Item Name`,\n",
    "       FIRST_VALUE(`Treatment Date`) OVER(PARTITION BY `Member Code`) AS delivery_date\n",
    "    FROM table \n",
    "    WHERE `Item Name` RLIKE '(?i)delivery'\n",
    "),\n",
    "Claims_table AS (\n",
    "    SELECT \n",
    "        *\n",
    "    FROM TABLE\n",
    ")\n",
    "SELECT \n",
    "    d.`Member Code`,\n",
    "    COUNT(c.`Claim Number`) AS claim_count,\n",
    "    c.`Treatment Date`\n",
    "FROM delivery_table AS d\n",
    "INNER JOIN Claims_table AS c \n",
    "    ON d.`Member Code`= c.`Member Code`\n",
    "WHERE c.`Treatment Date` BETWEEN d.delivery_date AND DATE_ADD(d.delivery_date, 60)\n",
    "GROUP BY d.`Member Code`,c.`Treatment Date`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "71a6ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maternity_Delivery.show()\n",
    "#Maternity_Delivery.count() # There are 2555 claims that meets the criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b84023",
   "metadata": {},
   "source": [
    "## Optical and Dental Claims for ages Less than 1 year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "248e0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt_den_1 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  *\n",
    "FROM table \n",
    "WHERE `Service Type` RLIKE '(?i)optical' AND `Age` < 1 OR `Service Type` RLIKE '(?i)dental' AND `Age` < 1\n",
    " \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d4c4b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opt_den_1.select(\"Member Code\",\"Service Type\",\"Age\").show()\n",
    "#Opt_den_1.count() # There 146 Claims with the criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a3ee",
   "metadata": {},
   "source": [
    "## Dental Abuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e4dfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dental_abuse = spark.sql(\"\"\"\n",
    "\n",
    "SELECT \n",
    "      `Claim Number`,\n",
    "      `Treatment Date`,\n",
    "       COUNT(`Claim Number`) AS No_of_Claims\n",
    "FROM \n",
    "     table\n",
    "WHERE \n",
    "     `Service Type` RLIKE '(?i)dental' \n",
    "GROUP BY \n",
    "     `Claim Number`,`Treatment Date`\n",
    "HAVING \n",
    "     No_of_Claims >= 3 \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e70e721d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5723"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dental_abuse.count() # There are 5,723 claims with this abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38eae547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dental_abuse.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa72f3c",
   "metadata": {},
   "source": [
    "## Dental Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7241aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dental_limit = spark.sql(\"\"\"\n",
    "SELECT *,\n",
    "       Next_treatment,\n",
    "       Last_treatment\n",
    "FROM\n",
    "    (SELECT *,\n",
    "           LEAD(`Treatment Date`) OVER(PARTITION BY `Member Code` ORDER BY `Treatment Date`) AS Next_treatment,\n",
    "           LAST_VALUE(`Treatment Date`) OVER(PARTITION BY `Member Code` ORDER BY `Treatment Date` ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS Last_treatment\n",
    "    FROM table\n",
    "    WHERE `Service Type` RLIKE '(?i)dental' AND datediff(`Policy Expiry Date`, `Treatment Date`) < 14\n",
    "    ) AS subquery\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fbdcf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Subtract 'Treatment Date' from 'Policy Expiry Date' and create a new column\n",
    "Dental_limit_select = Dental_limit_select.withColumn('Date_Difference', expr(\"datediff(`Policy Expiry Date`, `Treatment Date`)\"))\n",
    "\n",
    "# Select required columns\n",
    "Dental_limit_select = Dental_limit_select.select('Policy Expiry Date', 'Treatment Date', 'Member Code', 'Date_Difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5aafa436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some Inconsistency in the Policy Expiry Date . \n",
    "#|2021-07-19|2022-01-27|3241763|-192|\n",
    "\n",
    "# Dental_limit_select.show()\n",
    "# Dental_limit_select.count() #There are 2,113 records "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4ff57",
   "metadata": {},
   "source": [
    "## Optical Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b01e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optical_limit = spark.sql(\"\"\"\n",
    "SELECT *,\n",
    "       Next_treatment,\n",
    "       Last_treatment\n",
    "FROM\n",
    "    (SELECT *,\n",
    "           LEAD(`Treatment Date`) OVER(PARTITION BY `Member Code` ORDER BY `Treatment Date`) AS Next_treatment,\n",
    "           LAST_VALUE(`Treatment Date`) OVER(PARTITION BY `Member Code` ORDER BY `Treatment Date` ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS Last_treatment\n",
    "    FROM table\n",
    "    WHERE `Service Type` RLIKE '(?i)optical' AND datediff(`Policy Expiry Date`, `Treatment Date`) < 14\n",
    "    ) AS subquery\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c0bc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Subtract 'Treatment Date' from 'Policy Expiry Date' and create a new column\n",
    "Optical_limit_Selected = Optical_limit.withColumn('Date_Difference', expr(\"datediff(`Policy Expiry Date`, `Treatment Date`)\"))\n",
    "\n",
    "# Select required columns\n",
    "Optical_limit = Optical_limit_Selected.select('Policy Expiry Date', 'Treatment Date', 'Member Code', 'Date_Difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caf754a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+-----------+---------------+\n",
      "|Policy Expiry Date|Treatment Date|Member Code|Date_Difference|\n",
      "+------------------+--------------+-----------+---------------+\n",
      "|        2022-01-19|    2022-01-11|    5784637|              8|\n",
      "|        2022-02-13|    2022-02-08|    5136010|              5|\n",
      "|        2022-02-09|    2022-02-03|    6390210|              6|\n",
      "|        2022-02-16|    2022-02-10|    4107798|              6|\n",
      "|        2022-01-22|    2022-01-12|    5786529|             10|\n",
      "|        2022-01-22|    2022-01-11|    5786529|             11|\n",
      "|        2022-02-16|    2022-02-10|    4107798|              6|\n",
      "|        2022-02-06|    2022-02-02|    5819871|              4|\n",
      "|        2022-02-06|    2022-02-06|    5820318|              0|\n",
      "|        2022-02-03|    2022-01-30|    5807598|              4|\n",
      "|        2022-01-25|    2022-01-22|    5162306|              3|\n",
      "|        2022-01-31|    2022-01-18|    3903088|             13|\n",
      "|        2022-02-06|    2022-02-03|    5820080|              3|\n",
      "|        2022-02-06|    2022-02-05|    5820168|              1|\n",
      "|        2022-01-31|    2022-01-29|    6296170|              2|\n",
      "|        2022-02-03|    2022-03-08|    5807601|            -33|\n",
      "|        2022-03-22|    2022-03-17|    5052848|              5|\n",
      "|        2022-02-06|    2022-02-05|    5820209|              1|\n",
      "|        2022-03-24|    2022-03-13|    4455312|             11|\n",
      "|        2022-01-31|    2022-01-25|    3904204|              6|\n",
      "+------------------+--------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are some Inconsistency in the Policy Expiry Date . \n",
    "#|2022-02-03|2022-03-08|5807601|-33|\n",
    "Optical_limit.show()\n",
    "Optical_limit.count() # There are 1008 Record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea237be",
   "metadata": {},
   "source": [
    "## Unbundle services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08b6f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I used Regexp to get all records containing each words.\n",
    "Unbundle_services = spark.sql(\"\"\"\n",
    "SELECT \n",
    "       *\n",
    "FROM\n",
    "      table\n",
    "WHERE \n",
    "     `Item Name` RLIKE '(?i)(Lipid\\s*Profile|LDL|HDL|Cholesterol|Triglyceride)' AND `Service Type` = 'Lab' \n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Renal\\s*Profile|Sodium|Na|Potassium|K|Chloride|Urea|Creatine|Calcium|Bicarbonate)' AND `Service Type` = 'Lab'\n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Cardiac\\s*Enzyme|troponin|CK|Ck-MB)' AND `Service Type` = 'Lab'\n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Electrolyte|sodium|NA|Potassium|K|chloride|CL|magnesium|MG|calcium|CA|Phosphate|PO4|bicarbonates)' AND `Service Type` = 'Lab'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76f7ab75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unbundle_services.count() #There are 137,136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21a388be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparism , I checked using regexp with just package name\n",
    "\n",
    "Unbundle_services_2 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "       *\n",
    "FROM\n",
    "      table\n",
    "WHERE \n",
    "     `Item Name` RLIKE '(?i)(Lipid\\s*Profile)' AND `Service Type` = 'Lab' \n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Renal\\s*Profile)' AND `Service Type` = 'Lab'\n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Cardiac\\s*Enzyme)' AND `Service Type` = 'Lab'\n",
    "     OR\n",
    "     `Item Name` RLIKE '(?i)(Electrolyte)' AND `Service Type` = 'Lab'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d5708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbundle_services_2.select('Item Name','Claim Number','Service Type').show()\n",
    "# Unbundle_services_2.count() # There are 1,737 Records \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fc63d",
   "metadata": {},
   "source": [
    "## Work Related Claims with Relation self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9f481e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Work_related_claims = spark.sql(\"\"\"\n",
    "SELECT \n",
    "       *\n",
    "FROM\n",
    "      table\n",
    "WHERE \n",
    "     `Diagnosis Code` RLIKE '(?i)(s)' AND `Member Relationship` = 'Self' \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "420a7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work_related_claims.select(\"Member Relationship\",\"Diagnosis Code\").show()\n",
    "# Work_related_claims.count() #  There are 27,313 records "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628d0b7",
   "metadata": {},
   "source": [
    "## Infertility Claims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04812eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Infertility_claims = spark.sql(\"\"\"\n",
    "SELECT \n",
    "       *\n",
    "FROM\n",
    "      table\n",
    "WHERE \n",
    "     `Item Name` RLIKE '(?i)(Luteinizing\\s*hormone|Lh|Follicle\\s*stimulating\\s*hormone|FSH)' AND `Age` BETWEEN 15 AND 50 \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f28e9cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Infertility_claims.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f63878",
   "metadata": {},
   "source": [
    "## Herbal Medication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb3f1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Herbal Datasheet \n",
    "\n",
    "Herbal = spark.read.csv('Herbs.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e659a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Herbal.createOrReplaceTempView(\"Herbs\") # Create a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e703ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to join both Tables Using Spark SQL \n",
    "# INNER JOIN Return ALL Matching records on Item name / Ingredient column\n",
    "# There might be a better way to find these records \n",
    "Herbal_Medication = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM \n",
    "    table T\n",
    "INNER JOIN \n",
    "    Herbs H ON T.`Item Name` = H.`Ingredient`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2f06c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19471"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Herbal_Medication.count() #There are 19,471 records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6606ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herbal_Medication.select('H.Ingredient','T.Item Name').show(100,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
